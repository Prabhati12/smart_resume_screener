# -*- coding: utf-8 -*-
"""smart resume screener.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1uSgIxm0_MVm8JnLPZuQ2KhwMO0HujHQY
"""

# Use the latest, most capable, and fastest model for structured output
# This name is widely supported and confirmed for JSON schema requests.
MODEL = 'gemini-2.5-flash'
print(f"Using model: {MODEL}")
# ... rest of the client initialization

# Install the necessary libraries
!pip install google-genai pydantic pypdf
print("Dependencies installed.")

import os
from google import genai
from google.genai import types
from pydantic import BaseModel, Field
from typing import List, Optional
from google.colab import userdata

try:
    GEMINI_API_KEY = userdata.get('GEMINI_API_KEY')
    client = genai.Client(api_key=GEMINI_API_KEY)
except:
    print("Please set up your GEMINI_API_KEY in Colab Secrets (the key icon on the left panel).")
    # Fallback for direct input (less secure)
    # GEMINI_API_KEY = input("Enter your Gemini API Key: ")
    # client = genai.Client(api_key=GEMINI_API_KEY)

MODEL = 'gemini-2.5-flash'
print("Gemini client initialized.")

# --- 1. Structured Data Extraction Schema ---

class WorkExperience(BaseModel):
    """Schema for a single job role."""
    job_title: str = Field(description="The role title at the company.")
    company: str = Field(description="The name of the company.")
    duration_years: Optional[float] = Field(None, description="The duration in years (e.g., 2.5). Null if not easily determinable.")
    summary: str = Field(description="Brief (30 words max) summary of responsibilities.")

class Education(BaseModel):
    """Schema for an educational entry."""
    degree: str
    institution: str
    year_of_completion: Optional[int] = Field(None, description="The year of completion. Null if ongoing or not listed.")

class CandidateData(BaseModel):
    """The full structured data extracted from a resume."""
    candidate_name: str
    total_years_experience: Optional[float] = Field(None, description="Total computed years of work experience across all roles. Null if unknown.")
    skills: List[str] = Field(description="A list of core technical and soft skills. Prioritize technical skills.")
    work_experience: List[WorkExperience]
    education: List[Education]

# --- 2. Matching & Scoring Schema ---

class MatchResult(BaseModel):
    """The result of comparing a resume against a job description."""
    match_score: int = Field(..., ge=1, le=10, description="Overall fit score from 1 (low) to 10 (high).")
    justification: str = Field(description="A concise summary of the score (max 100 words).")
    key_matches: List[str] = Field(description="3-5 key strengths or matched requirements.")
    key_gaps: List[str] = Field(description="1-3 critical missing skills or experience gaps.")

print("Pydantic schemas defined.")

from google.colab import files
from pypdf import PdfReader
import io

# 1. Upload the Resume PDF
uploaded = files.upload()
if not uploaded:
    raise Exception("No file uploaded. Please upload a PDF resume.")

# Assuming a single file upload
file_name = list(uploaded.keys())[0]
pdf_data = uploaded[file_name]

# 2. Extract text using pypdf
def extract_text_from_pdf_colab(pdf_data: bytes) -> str:
    reader = PdfReader(io.BytesIO(pdf_data))
    text = ""
    for page in reader.pages:
        text += page.extract_text()
    return text

resume_text = extract_text_from_pdf_colab(pdf_data)
print(f"Successfully extracted text from {file_name} ({len(resume_text)} characters).")

# 3. Define the Job Description
JOB_DESCRIPTION = """
We are seeking a Senior Data Scientist with a minimum of 5 years experience,
proficient in Python (Pandas, Scikit-learn, PyTorch), advanced SQL for data
warehousing, and hands-on experience deploying models using Docker/Kubernetes.
A Master's degree in a quantitative field is mandatory.
"""
print("\nJob Description Loaded.")

import json

def process_resume_and_match(resume_text: str, job_description: str) -> dict:
    """Performs structured extraction and semantic matching."""

    # --- LLM Call 1: Structured Data Extraction ---
    print("\n--- 1. Performing Structured Data Extraction ---")

    extraction_prompt = f"Analyze the following RESUME TEXT and extract the structured data according to the provided schema. RESUME TEXT: --- {resume_text} ---"

    config_1 = types.GenerateContentConfig(
        response_mime_type="application/json",
        response_schema=CandidateData,
    )

    response_1 = client.models.generate_content(
        model=MODEL,
        contents=extraction_prompt,
        config=config_1,
    )

    # Validate and parse the structured output
    candidate_data_json = response_1.text
    candidate_data = CandidateData.model_validate_json(candidate_data_json)
    print("Extraction Complete.")

    # --- LLM Call 2: Semantic Matching & Scoring ---
    print("\n--- 2. Performing Semantic Matching and Scoring ---")

    scoring_prompt = f"""
    JOB DESCRIPTION: {job_description}
    ---
    CANDIDATE PROFILE (Structured JSON): {candidate_data_json}
    ---
    As an expert HR Analyst, compare the CANDIDATE PROFILE against the JOB DESCRIPTION.
    Rate the overall fit on a scale of 1 to 10. Provide a detailed justification, key matches, and key gaps in the required JSON format.
    """

    config_2 = types.GenerateContentConfig(
        response_mime_type="application/json",
        response_schema=MatchResult,
    )

    response_2 = client.models.generate_content(
        model=MODEL,
        contents=scoring_prompt,
        config=config_2,
    )

    match_result = MatchResult.model_validate_json(response_2.text)
    print("Scoring Complete.")

    return {
        "candidate_data": candidate_data.model_dump(),
        "match_result": match_result.model_dump()
    }

# Execute the combined function
results = process_resume_and_match(resume_text, JOB_DESCRIPTION)

from IPython.display import display, Markdown

# Displaying Candidate Data
print("="*50)
print("CANDIDATE STRUCTURED DATA (for DB)")
print("="*50)
print(json.dumps(results['candidate_data'], indent=2))

# Displaying Match Score and Justification
match = results['match_result']

display(Markdown(f"""
---
##MATCH SCORECARD (LLM Output)

| Metric | Detail |
| :--- | :--- |
| **Match Score (1-10)** | **{match['match_score']} / 10** |
| **Justification** | {match['justification']} |

### Key Strengths (Matches)
* {chr(10).join(match['key_matches'])}

### Critical Gaps (Weaknesses)
* {chr(10).join(match['key_gaps'])}
---
"""))